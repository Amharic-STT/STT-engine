{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6669506e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join('../scripts')))\n",
    "\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.io import wavfile #for audio processing\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import * \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12218174",
   "metadata": {},
   "outputs": [],
   "source": [
    "import helper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83684aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_augmentation import Data_Augmentation\n",
    "from data_loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "415a735b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate = 8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9eb64693",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    \n",
    "    def __init__(self, translations):\n",
    "        self.translations = translations\n",
    "        self.unk = -1\n",
    "        \n",
    "    def build_dict(self):\n",
    "        text = ''\n",
    "        for t in self.translations:\n",
    "            text += t\n",
    "        \n",
    "        char_counts = Counter(text)\n",
    "        sorted_vocab = sorted(char_counts, key=char_counts.get, reverse=True)\n",
    "        int_to_char = {ii: word for ii, word in enumerate(sorted_vocab, 1)}\n",
    "\n",
    "        char_to_int = {word: ii for ii, word in int_to_char.items()}\n",
    "        \n",
    "        return int_to_char, char_to_int\n",
    "    \n",
    "    def encode(self, sent, char_to_int):\n",
    "        \n",
    "        encoded = []\n",
    "        char_list = list(sent)\n",
    "        for c in char_list:\n",
    "            try:\n",
    "                encoded.append(char_to_int[c])\n",
    "            \n",
    "            except KeyError:\n",
    "                encoded.append(self.unk)\n",
    "        return encoded\n",
    "    \n",
    "    def decode_text(self, encoded_chars, int_to_char):\n",
    "        \n",
    "        decoded = ''\n",
    "        for e in encoded_chars:\n",
    "            try:\n",
    "                decoded += e\n",
    "            \n",
    "            except KeyError:\n",
    "                decoded += ''\n",
    "        \n",
    "        return decoded\n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "         \n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9141886e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self,  translations, audios, batch_size=32, shuffle=True):\n",
    "        self.audios = audios\n",
    "        self.labels = translations\n",
    "        self.batch_size = batch_size\n",
    "        self.len = int(np.floor(len(self.labels) / self.batch_size))\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "        self.tokenizer = Tokenizer(translations)\n",
    "        self.int_to_char, self.char_to_int = tokenizer.build_dict()\n",
    "        \n",
    "        self.cur_index = 0\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    def encode_text(self, translations):\n",
    "        encoded_trans =  []\n",
    "        \n",
    "        for t in translations:\n",
    "            encoded = self.tokenizer.encode(t, self.char_to_int)\n",
    "            encoded_trans.append(encoded)\n",
    "        \n",
    "        return encoded_trans\n",
    "    \n",
    "    def get_max_len(self, items):\n",
    "        maximum = 0\n",
    "        for i in items:\n",
    "            if len(i) > maximum:\n",
    "                maximum = len(i)\n",
    "                \n",
    "        return maximum\n",
    "\n",
    "            \n",
    "    def __data_generation(self, batch_translations, batch_audios):\n",
    "     \n",
    "        self.cur_index = 0\n",
    "        encoded_trans = self.encode_text(batch_translations)\n",
    "        \n",
    "        maximum_trans_len = self.get_max_len(encoded_trans)\n",
    "        maximum_audio_len = self.get_max_len(batch_audios)\n",
    "        \n",
    "        \n",
    "        encoded_trans_np = np.zeros((len(encoded_trans), maximum_trans_len), dtype=\"int64\")\n",
    "        padded_audios_np = np.zeros((len(batch_audios), maximum_audio_len), dtype=\"float32\")\n",
    "        \n",
    "        label_length = np.zeros(padded_audios_np.shape[0], dtype=\"int64\")\n",
    "        input_length = np.zeros(encoded_trans_np.shape[0], dtype=\"int64\")\n",
    "        \n",
    "        \n",
    "        ind = 0\n",
    "        for trans, audio in zip(encoded_trans, batch_audios):\n",
    "            encoded_trans_np[ind,0:len(trans)] = trans\n",
    "            label_length[ind] = len(trans)\n",
    "            \n",
    "            padded_audio = np.pad(audio, (0, maximum_audio_len - len(audio)), mode = 'constant', constant_values=0)\n",
    "            \n",
    "            padded_audios_np[ind, ] = padded_audio\n",
    "            input_length[ind] = len(audio)\n",
    "            \n",
    "            ind += 1\n",
    "        \n",
    "        outputs = {'ctc': np.zeros([self.batch_size])}\n",
    "        inputs = {'the_input':   tf.convert_to_tensor(padded_audios_np), \n",
    "                  'the_labels':   tf.convert_to_tensor(encoded_trans_np), \n",
    "                  'input_length':   tf.convert_to_tensor(input_length), \n",
    "                  'label_length':   tf.convert_to_tensor(label_length) \n",
    "                 }\n",
    "        \n",
    "        return (inputs, outputs)\n",
    "            \n",
    "    def on_epoch_end(self):\n",
    "                \n",
    "        self.indexes = np.arange(self.len*self.batch_size)\n",
    "\n",
    "        if self.shuffle == True:\n",
    "\n",
    "            self.indexes = self.indexes.reshape(int(self.len), int(self.batch_size))\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "            for i in range(self.len):\n",
    "                np.random.shuffle(self.indexes[i])\n",
    "\n",
    "            self.indexes = self.indexes.reshape(int(self.len*self.batch_size))\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.indexes[int(index*self.batch_size):int((index+1)*self.batch_size)]\n",
    "        \n",
    "        self.cur_index += self.batch_size\n",
    "        \n",
    "        if  self.cur_index >= len(self.labels):\n",
    "            self.cur_index = 0\n",
    "\n",
    "        batch_labels = [self.labels[int(k)] for k in indexes]\n",
    "        batch_audios = [self.audios[int(k)] for k in indexes]\n",
    "        \n",
    "        batch_labels = self.labels[self.cur_index:  self.cur_index + self.batch_size]\n",
    "        batch_audios = self.audios[ self.cur_index:  self.cur_index + self.batch_size]\n",
    "    \n",
    "        \n",
    "        return  self.__data_generation(batch_labels, batch_audios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25b5a221",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogMelSpectrogram(tf.keras.layers.Layer):\n",
    "    \"\"\"Compute log-magnitude mel-scaled spectrograms.\"\"\"\n",
    "\n",
    "    def __init__(self, sample_rate, fft_size, hop_size, n_mels,\n",
    "                 f_min=0.0, f_max=None, **kwargs):\n",
    "        super(LogMelSpectrogram, self).__init__(**kwargs)\n",
    "        self.sample_rate = sample_rate\n",
    "        self.fft_size = fft_size\n",
    "        self.hop_size = hop_size\n",
    "        self.n_mels = n_mels\n",
    "        self.f_min = f_min\n",
    "        self.f_max = f_max if f_max else sample_rate / 2\n",
    "        self.mel_filterbank = tf.signal.linear_to_mel_weight_matrix(\n",
    "            num_mel_bins=self.n_mels,\n",
    "            num_spectrogram_bins=fft_size // 2 + 1,\n",
    "            sample_rate=self.sample_rate,\n",
    "            lower_edge_hertz=self.f_min,\n",
    "            upper_edge_hertz=self.f_max)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.non_trainable_weights.append(self.mel_filterbank)\n",
    "        super(LogMelSpectrogram, self).build(input_shape)\n",
    "\n",
    "    def call(self, waveforms):\n",
    "        \"\"\"Forward pass.\n",
    "        Parameters\n",
    "        ----------\n",
    "        waveforms : tf.Tensor, shape = (None, n_samples)\n",
    "            A Batch of mono waveforms.\n",
    "        Returns\n",
    "        -------\n",
    "        log_mel_spectrograms : (tf.Tensor), shape = (None, time, freq, ch)\n",
    "            The corresponding batch of log-mel-spectrograms\n",
    "        \"\"\"\n",
    "        def _tf_log10(x):\n",
    "            numerator = tf.math.log(x)\n",
    "            denominator = tf.math.log(tf.constant(10, dtype=numerator.dtype))\n",
    "            return numerator / denominator\n",
    "\n",
    "        def power_to_db(magnitude, amin=1e-16, top_db=80.0):\n",
    "            \"\"\"\n",
    "            https://librosa.github.io/librosa/generated/librosa.core.power_to_db.html\n",
    "            \"\"\"\n",
    "            ref_value = tf.reduce_max(magnitude)\n",
    "            log_spec = 10.0 * _tf_log10(tf.maximum(amin, magnitude))\n",
    "            log_spec -= 10.0 * _tf_log10(tf.maximum(amin, ref_value))\n",
    "            log_spec = tf.maximum(log_spec, tf.reduce_max(log_spec) - top_db)\n",
    "\n",
    "            return log_spec\n",
    "\n",
    "        spectrograms = tf.signal.stft(waveforms,\n",
    "                                      frame_length=self.fft_size,\n",
    "                                      frame_step=self.hop_size,\n",
    "                                      pad_end=False)\n",
    "\n",
    "        magnitude_spectrograms = tf.abs(spectrograms)\n",
    "\n",
    "        mel_spectrograms = tf.matmul(tf.square(magnitude_spectrograms),\n",
    "                                     self.mel_filterbank)\n",
    "\n",
    "        log_mel_spectrograms = power_to_db(mel_spectrograms)\n",
    "\n",
    "        # add channel dimension\n",
    "        log_mel_spectrograms = tf.expand_dims(log_mel_spectrograms, 3)\n",
    "\n",
    "        return log_mel_spectrograms\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'fft_size': self.fft_size,\n",
    "            'hop_size': self.hop_size,\n",
    "            'n_mels': self.n_mels,\n",
    "            'sample_rate': self.sample_rate,\n",
    "            'f_min': self.f_min,\n",
    "            'f_max': self.f_max,\n",
    "        }\n",
    "        config.update(super(LogMelSpectrogram, self).get_config())\n",
    "\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f51f7620",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessin_model(sample_rate, fft_size, frame_step, n_mels, mfcc=False):\n",
    "\n",
    "    input_data = Input(name='input', shape=(None,), dtype=\"float32\")\n",
    "    featLayer = LogMelSpectrogram(\n",
    "        fft_size=fft_size,\n",
    "        hop_size=frame_step,\n",
    "        n_mels=n_mels,\n",
    "        \n",
    "        sample_rate=sample_rate,\n",
    "        f_min=0.0,\n",
    "        \n",
    "        f_max=int(sample_rate / 2)\n",
    "    )(input_data)\n",
    "    \n",
    "    x = BatchNormalization()(featLayer)\n",
    "    model = Model(inputs=input_data, outputs=x, name=\"preprocessin_model\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ad3a64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BidirectionalRNN(input_dim, batch_size, sample_rate=22000,\n",
    "                     rnn_layers=2, units=400, drop_out=0.5, act='tanh', output_dim=224):\n",
    "\n",
    "    input_data = Input(name='the_input', shape=(\n",
    "        None, input_dim), batch_size=batch_size)\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    x = Bidirectional(LSTM(units,  activation=act,\n",
    "                      return_sequences=True, implementation=2))(input_data)\n",
    "    \n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(drop_out)(x)\n",
    "\n",
    "    for i in range(rnn_layers - 2):\n",
    "        x = Bidirectional(\n",
    "            LSTM(units, activation=act, return_sequences=True))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(drop_out)(x)\n",
    "\n",
    "    x = Bidirectional(LSTM(units,  activation=act,\n",
    "                      return_sequences=True, implementation=2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(drop_out)(x)\n",
    "\n",
    "    time_dense = TimeDistributed(Dense(output_dim))(x)\n",
    "\n",
    "    y_pred = Activation('softmax', name='softmax')(time_dense)\n",
    "\n",
    "    model = Model(inputs=input_data, outputs=y_pred, name=\"BidirectionalRNN\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55768adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_rnn_model(input_dim, output_dim=224):\n",
    "\n",
    "    input_data = Input(name='the_input', shape=(None, input_dim))\n",
    "    simp_rnn = GRU(output_dim, return_sequences=True,\n",
    "                   implementation=2, name='rnn')(input_data)\n",
    "    y_pred = Activation('softmax', name='softmax')(simp_rnn)\n",
    "    model = Model(inputs=input_data, outputs=y_pred, name=\"simple_rnn_model\")\n",
    "    model.output_length = lambda x: x\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3773ae03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910f49f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_lengths_lambda_func(args):\n",
    "    hop_size = frame_step\n",
    "    input_length = args\n",
    "    return tf.cast(tf.math.ceil(input_length/hop_size)-1, dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e623cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ctc_loss(model_builder):\n",
    "    the_labels      = Input(name='the_labels',      shape=(None,), dtype='float32')\n",
    "    input_lengths   = Input(name='input_length',    shape=(1,), dtype='float32')\n",
    "    label_lengths   = Input(name='label_length',    shape=(1,), dtype='float32')\n",
    "\n",
    "    input_lengths2 = Lambda(input_lengths_lambda_func)(input_lengths)\n",
    "    if model_builder.output_length:\n",
    "         output_lengths  = Lambda(model_builder.output_length)(input_lengths2) - 1\n",
    "    else:\n",
    "         output_lengths  = input_lengths2\n",
    "    \n",
    "    # CTC loss is implemented in a lambda layer\n",
    "    loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([model_builder.output, the_labels, output_lengths, label_lengths])\n",
    "    model = Model( inputs=[model_builder.input, the_labels, input_lengths, label_lengths],  outputs=loss_out)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d95ff9f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SGD' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-e2833a17a3f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m           \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.002\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnesterov\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclipnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m           ):    \n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SGD' is not defined"
     ]
    }
   ],
   "source": [
    "def train(model_builder, \n",
    "          data_len,\n",
    "          data_gen,\n",
    "          batch_size = 25,\n",
    "          epochs=20, \n",
    "          verbose=1,\n",
    "          optimizer=SGD(learning_rate=0.002, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=5),\n",
    "          ):    \n",
    "              \n",
    "    model = add_ctc_loss(model_builder)\n",
    "\n",
    "    model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=optimizer)\n",
    "    print(model.summary())\n",
    "\n",
    "\n",
    "    hist = model.fit_generator(generator=data_gen,\n",
    "                               epochs=epochs,\n",
    "                               verbose=verbose, \n",
    "                               use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34e1d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "audios = []\n",
    "for label in audio_obj:\n",
    "    audios.append(audio_obj[label][0])\n",
    "    \n",
    "translations = []\n",
    "for label in audio_obj:\n",
    "    translations.append(translation_obj[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72b70ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(translations)\n",
    "int_to_char, char_to_int = tokenizer.build_dict()\n",
    "sample = translations[0]\n",
    "encoded = tokenizer.encode(sample, char_to_int)\n",
    "decoded = tokenizer.decode_text(sample, encoded)\n",
    "\n",
    "print(f\"sample snt: {sample}\")\n",
    "print(f\"encoded snt: {encoded}\")\n",
    "print(f\"decoed snt: {decoded}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ac14c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sample_rate = 22000\n",
    "fft_size = 1024\n",
    "frame_step = 512\n",
    "n_mels = 128\n",
    "\n",
    "batch_size = 100\n",
    "epochs = 20\n",
    "data_len = len(translations)\n",
    "output_dim = len(char_to_int) + 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f356018a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dg = DataGenerator(translations, audios, batch_size)\n",
    "preprocess_model = preprocessin_model(sample_rate, fft_size, frame_step, n_mels)\n",
    "preprocess_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e25f796",
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_model = simple_rnn_model(n_mels, output_dim)\n",
    "speech_model.summary()\n",
    "# speech_model = BidirectionalRNN(n_mels, output_dim=output_dim)\n",
    "# speech_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9416797",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(output_dim, custom_model, preprocess_model, mfcc=False, calc=None):\n",
    "\n",
    "    input_audios = Input(name='the_input', shape=(None,))\n",
    "    pre = preprocess_model(input_audios)\n",
    "    pre = tf.squeeze(pre, [3])\n",
    "\n",
    "    y_pred = custom_model(pre)\n",
    "    model = Model(inputs=input_audios, outputs=y_pred, name=\"model_builder\")\n",
    "    model.output_length = calc\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d849fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(output_dim, speech_model, preprocess_model)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1580cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlflow.set_experiment('Speech Model-RNN-baseline')\n",
    "# mlflow.tensorflow.autolog()\n",
    "train(model, 100, dg, epochs=20,  batch_size=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
